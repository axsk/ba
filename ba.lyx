#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman charter
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\shape up
An overview over PCCA+ and its application to eye tracking data
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Section

\shape up
Introduction
\end_layout

\begin_layout Standard
In this thesis I will try to give an overview over the PCCA+ algorithm,
 as well as it's application.
\end_layout

\begin_layout Standard
I therefore will cover the basic PCCA+ setting, as primarily investigated
 by Weber in his dissertation
\begin_inset CommandInset citation
LatexCommand cite
key "Weber2006"

\end_inset

.
\end_layout

\begin_layout Standard
After an introduction to theoretical setting I will explain the PCCA+ algorithm
 and discuss some of its developments.
 Finally I will showcase an application to human eye tracking data used
 for object recognition.
\end_layout

\begin_layout Section

\shape up
Theoretical background
\end_layout

\begin_layout Subsection
Introduction to Markov chains
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $S:=\left\{ 1,...,N\right\} $
\end_inset

 for 
\begin_inset Formula $N\in\mathbb{N}$
\end_inset

.
 A Markov chain on 
\begin_inset Formula $S$
\end_inset

 is a stochastic process, consisting of a sequence of random variables 
\begin_inset Formula $X_{i}:\Omega\rightarrow S$
\end_inset

, 
\begin_inset Formula $i\in\mathbb{N}$
\end_inset

 satisfying the Markov property: 
\begin_inset Formula 
\[
P(X_{t+1}=x|X_{1}=x_{1},X_{2}=X_{2},...,X_{t}=x_{t})=P(X_{t+1}=x|X_{t}=x_{t})\,\forall t\in\mathbb{N}.
\]

\end_inset

It is common to interpret S as the state space of possible outcomes of measureme
nts at the time 
\begin_inset Formula $t$
\end_inset

 represented by 
\begin_inset Formula $X_{t}$
\end_inset

.
 The Markov property assures, that the transitions to the next timestep
 
\begin_inset Formula $t+1$
\end_inset

 only depend on the current state 
\begin_inset Formula $x_{t}$
\end_inset

.
 This means that the process at time 
\begin_inset Formula $t$
\end_inset

 has no memory of its previous history 
\begin_inset Formula $(x_{1},...,x_{t-1})$
\end_inset

, thus this also sometimes called the memoryless property.
\end_layout

\begin_layout Standard
We will furthermore assume that 
\begin_inset Formula $S$
\end_inset

 is finite and that the process is autonomous, i.e.
 not explicitly depending on the time:
\begin_inset Formula 
\[
P(X_{t+1}=x|X_{t}=y)=P(X_{t}=x|X_{t-1}=y)\forall t\in\mathbb{N}
\]

\end_inset


\end_layout

\begin_layout Standard
This does not realy impose a restriction as any non-autonomous process can
 be turned into an autonomous one.
 By adding all possible times to the state space 
\begin_inset Formula $S$
\end_inset

 taking the cartesian product 
\begin_inset Formula $S':=\mathbb{N}\times S$
\end_inset

 the explicit time-dependence of the process on 
\begin_inset Formula $S$
\end_inset

 can be implicitly subsumed by an autonomous process on 
\begin_inset Formula $S'$
\end_inset

.
\end_layout

\begin_layout Standard
For finite 
\begin_inset Formula $S$
\end_inset

 we can, enumerating all states in 
\begin_inset Formula $S$
\end_inset

, encode the whole process in the transition matrix
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P_{ij}:=P\left(X_{t+1}=j|X_{t}=i\right)
\]

\end_inset


\end_layout

\begin_layout Standard
A 
\emph on
stationary distribution
\emph default
 is a row vector 
\begin_inset Formula $\pi$
\end_inset

 satisfying
\begin_inset Formula 
\[
\pi P=\pi
\]

\end_inset


\end_layout

\begin_layout Standard
A markov chain is called 
\emph on
reversible
\emph default
 if there exists a 
\emph on
stationary distribution
\emph default
 
\begin_inset Formula $\pi$
\end_inset

 satisfying the detailed balance equation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\pi_{i}P_{ij}=\pi_{j}P_{ji}\label{eq:db}
\end{equation}

\end_inset

which assures equal back and forth transitions between any two states 
\begin_inset Formula $i,\, j$
\end_inset

, weighted by their
\emph on
 
\emph default
stationary distribution 
\begin_inset Formula $\pi_{i}$
\end_inset

, 
\begin_inset Formula $\pi_{j}$
\end_inset

.
\end_layout

\begin_layout Standard
Introducing the diagonal matrix 
\begin_inset Formula 
\[
D_{\pi}:=\text{diag}\left(\pi\right)
\]

\end_inset

this can also be written in matrix notation as 
\begin_inset Formula 
\[
D_{\pi}P=P^{T}D_{\pi}.
\]

\end_inset


\end_layout

\begin_layout Subsection
Discretization of the state space
\end_layout

\begin_layout Standard
Although we only consider a discrete state space in this thesis, the results
 are extensible to continous state spaces as well.
 
\end_layout

\begin_layout Standard
The easiest way is using a set-based discretization, dividing the state
 space into a finite mesh of subsets.
\end_layout

\begin_layout Standard
For high dimensional state spaces, as for example met in molecular dynamics,
 this approach exhibits the curse of dimensionality, as the size of the
 mesh grows exponentially with the dimensions.
 As solution to this problem Weber developed a meshless version of PCCA+
 using a global Galerkin discretization
\begin_inset CommandInset citation
LatexCommand cite
key "Weber2006"

\end_inset

.
\end_layout

\begin_layout Subsection
Clustering of the state space
\end_layout

\begin_layout Standard
As the goal of PCCA+ is to reduce the complexity of analysis of the markov
 chain by a dimension reduction we will now introduce the concept of clustering,
 that is subsuming different states of the state space to a smaller set
 of 
\begin_inset Formula $n\in\mathbb{N}$
\end_inset

 clusters 
\begin_inset Formula $C:=\left\{ 1,...,n\right\} $
\end_inset

.
\end_layout

\begin_layout Standard
The simplest possibility is assigning each state 
\begin_inset Formula $k\in S$
\end_inset

 to a cluster 
\begin_inset Formula $i\in C$
\end_inset

, which can be encoded by means of the 
\emph on
characteristic vector
\emph default
 
\begin_inset Formula $\chi_{i}\in\left\{ 0,1\right\} ^{N}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\chi_{i,k}=\begin{cases}
1, & \text{if state \ensuremath{k}}\text{ belongs to cluster }i\\
0, & \text{else }
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Standard
This 
\emph on
crisp clustering 
\emph default
approach, used by 
\emph on
Perron Cluster Analysis
\emph default
 (PCCA) of Deuflhard et al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Deuflhard2000"

\end_inset

, has the disadvantage of not beeing robust against small pertubations,
 as continious changes in 
\begin_inset Formula $P$
\end_inset

 finally result in discontinous changes in the clustering.
\end_layout

\begin_layout Standard
Weber and Galliat, Deuflhard and Weber therefore developed a robust version,
 
\emph on
Robust Perron Cluster Analyis
\emph default
 (PCCA+), by making use of a 
\emph on
fuzzy clustering
\emph default
 representing each cluster by an
\emph on
 almost characteristic vector 
\begin_inset Formula 
\begin{equation}
\chi_{i}\in\left[0,1\right]^{n}.\label{eq:pos}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
A
\emph on
lmost characteristic vectors 
\begin_inset Formula $\left\{ \chi_{i}\right\} _{i=1}^{n}$
\end_inset


\emph default
 satisfying the partition of unity property
\begin_inset Formula 
\begin{equation}
\sum_{i=1}^{n}\chi_{i}=1\label{eq:pu}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
are called 
\emph on
membership vectors
\emph default
 as they describe the relative membership of each state to each cluster.
\end_layout

\begin_layout Standard
We will refer to the matrix collection 
\begin_inset Formula $\chi:=\left(\chi_{i}\right)_{i=1}^{n}\in\mathbb{R}^{N\times n}$
\end_inset

 of the 
\emph on
membership vectors
\emph default
 as a 
\emph on
clustering
\emph default
, whereas in literature it is also referred to as 
\emph on
conformations.
\end_layout

\begin_layout Subsection
Galerkin projection of the transition matrix
\end_layout

\begin_layout Subsubsection
The coupling matrix
\end_layout

\begin_layout Standard
To represent the dynamics on the reduced/clustered state space in the case
 of a 
\emph on
crisp clustering
\emph default
 
\begin_inset Formula $\chi$
\end_inset

, i.e.
 
\begin_inset Formula $\chi_{i}\in\left\{ 0,1\right\} $
\end_inset

, Deuflhard et al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Deuflhard2000"

\end_inset

 introduced the 
\emph on
coupling matrix
\emph default
 
\emph on

\begin_inset Formula 
\[
W_{ij}:=\frac{\left\langle \chi_{j},P\chi_{i}\right\rangle _{\pi}}{\left\langle \chi_{i},1\right\rangle _{\pi}}=\frac{\chi_{j}^{T}D_{\pi}P\chi_{i}}{\pi^{T}\chi_{i}}.
\]

\end_inset


\emph default
The entries 
\begin_inset Formula $W_{ij}$
\end_inset

 can thus be interpreted as conditional transition probability from cluster
 
\begin_inset Formula $i$
\end_inset

 to cluster 
\begin_inset Formula $j$
\end_inset

, given the starting distribution 
\begin_inset Formula $\pi$
\end_inset


\emph on
.
\end_layout

\begin_layout Standard
In the 
\emph on
fuzzy clustering 
\emph default
setting the problem arises, that it is no more clear which state belongs
 to which cluster.
 I therefore propose to interpret the membershipership of state 
\begin_inset Formula $j$
\end_inset

 to cluster 
\begin_inset Formula $\chi_{i}$
\end_inset

, 
\begin_inset Formula $\chi_{ij}$
\end_inset

, as probability of measuring/counting state 
\begin_inset Formula $j$
\end_inset

 as cluster 
\begin_inset Formula $\chi_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
Then 
\begin_inset Formula $W_{ij}$
\end_inset

 denotes the expectation value for measuring cluster 
\begin_inset Formula $\chi_{j}$
\end_inset

 after propagating the density given by 
\begin_inset Formula $\chi_{i}$
\end_inset

 weighted by 
\begin_inset Formula $\pi$
\end_inset

.
\end_layout

\begin_layout Standard
Note however that even if no real transitions are actually happening in
 the state space, we still may count transitions between clusters, as shown
 in example 3.
\end_layout

\begin_layout Subsubsection
The propagator matrix
\end_layout

\begin_layout Standard
Unfortunately the projection via the 
\emph on
coupling matrix 
\emph default
does not commute with time propagation, necessary for time-scale preservation,
 which is desired for long term analysis of the markov chain (as in bio/med...).
\end_layout

\begin_layout Standard
Therefore Kube and Weber 
\begin_inset CommandInset citation
LatexCommand cite
key "Kube2007"

\end_inset

 proposed the 
\emph on
coarse propagator matrix
\emph default
 
\emph on

\begin_inset Formula 
\begin{equation}
P_{C}:=\left(\chi^{T}D_{\pi}\chi\right)^{-1}\chi^{T}D_{\pi}P\chi,\label{eq:pc}
\end{equation}

\end_inset


\emph default
which coincides with the 
\emph on
coupling matrix 
\begin_inset Formula $W$
\end_inset

 
\emph default
in the 
\emph on
crisp clustering
\emph default
 setting.
\end_layout

\begin_layout Standard
Assuming that 
\begin_inset Formula $\chi$
\end_inset

 is a linear combination of vectors spanning an 
\begin_inset Formula $P$
\end_inset

-invariant subspace satisfying an orthonormality condition, as will be satisfied
 in the PCCA+ approach, it has the advantage that discretization via 
\begin_inset Formula $\chi$
\end_inset

 and time propagation commute, i.e.
 
\begin_inset Formula 
\begin{equation}
P\chi=\chi P_{C}.\label{eq:com}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This property ensures of that the 
\emph on
coupling matrix 
\emph default
represents the right dynamics of the underlying markov chain on 
\begin_inset Formula $S$
\end_inset

 on the reduced clustered state space, even for iterative application, i.e.
 
\begin_inset Formula $P^{n}\chi=\chi P_{C}^{n}$
\end_inset

,
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:comm"

\end_inset

Let 
\begin_inset Formula $\chi=XA$
\end_inset

, 
\begin_inset Formula $X\in\mathbb{R}^{N\times n}$
\end_inset

, 
\begin_inset Formula $A\in\mathbb{R}^{n\times n}$
\end_inset

 satisfying the subspace condition
\begin_inset Formula 
\begin{equation}
PX=X\Lambda\label{eq:ss}
\end{equation}

\end_inset

for some 
\begin_inset Formula $\Lambda\in\mathbb{R}^{n\times n}$
\end_inset

 and the orthonormality condition
\begin_inset Formula 
\begin{equation}
X^{T}D_{\pi}X=I.\label{eq:on}
\end{equation}

\end_inset


\end_layout

\begin_layout Theorem
Then the 
\begin_inset Formula $P_{C}$
\end_inset

 is conjugate to 
\begin_inset Formula $\Lambda$
\end_inset

 and discretization-propagation commutativity 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:com"

\end_inset

 holds.
\end_layout

\begin_layout Proof
We calculate
\begin_inset Formula 
\begin{eqnarray}
P_{C} & = & \left(\chi^{T}D_{\pi}\chi\right)^{-1}\chi^{T}D_{\pi}P\chi\nonumber \\
 & = & \left(A^{T}X^{T}D_{\pi}XA\right)^{-1}A^{T}X^{T}D_{\pi}X\Lambda A\nonumber \\
 & = & \left(A^{T}A\right)^{-1}\left(A^{T}\Lambda A\right)\nonumber \\
 & = & A^{-1}\Lambda A,\label{eq:conj}
\end{eqnarray}

\end_inset

which implies
\begin_inset Formula 
\[
P\chi=PXA=X\Lambda A=XAA^{-1}\Lambda A=\chi P_{C}.
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Compatibility
\end_layout

\begin_layout Standard
As noted, the 
\emph on
propagator matrix
\emph default
 can have negative entries, thus prohibiting a stochastic interpretation.
 
\end_layout

\begin_layout Standard
But I think the following consideration might help.
 Consider the inverted part of the 
\emph on
propagator matrix
\emph default
,
\emph on
 
\begin_inset Formula $\chi^{T}D_{\pi}\chi$
\end_inset


\emph default
.
 It computes the overlap of all clusters with each other, weighted with
 the distribution 
\begin_inset Formula $\pi$
\end_inset

.
 If we have overlap between different clusters, we also count 
\begin_inset Quotes eld
\end_inset

transitions
\begin_inset Quotes erd
\end_inset

 in the denominator 
\begin_inset Formula $\chi^{T}D_{\pi}P\chi$
\end_inset

 just due to the effect of the cluster mixing without any underlying dynamics.
 
\begin_inset Formula $\chi^{T}D_{\pi}\chi$
\end_inset

 computes the amount of transitions which are just due to the overlap (
\begin_inset Formula $P=\text{Id}$
\end_inset

), and therfore applying 
\begin_inset Formula $\left(\chi^{T}D_{\pi}\chi\right)^{-1}$
\end_inset

 reverts this amount, removing the cluster induced transitions, leaving
 just the underlying dynamics.
\end_layout

\begin_layout Standard
We can furthermore consider 
\begin_inset Formula $\chi:\left[0,1\right]^{N}\rightarrow\left[0,1\right]^{n}$
\end_inset

 restricted to its preimage as a bijection.We then can compute 
\begin_inset Formula $P_{C}=\chi^{-1}P\chi$
\end_inset

, i.e.
 
\begin_inset Formula $P_{C}$
\end_inset

 is just 
\begin_inset Formula $P$
\end_inset

 restricted to the smaller set, given to the basis of clusters.
\end_layout

\begin_layout Standard
To interpret this stochastically we need to return to the basis of states,
 weight with 
\begin_inset Formula $\pi$
\end_inset

, measure the overlap with the other clusters and normalize to the number
 of transitions, which leads to the previously introduced 
\begin_inset Formula $W=diag()^{-1}\left(\chi^{T}D_{\pi}\chi\right)P_{C}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Metastability
\end_layout

\begin_layout Standard
//baustelle
\end_layout

\begin_layout Standard
Deuflhard et.
 al
\begin_inset CommandInset citation
LatexCommand cite
key "Deuflhard2000"

\end_inset

 (?) introduced the notion of metastabililty, defined as the trace of the
 
\emph on
coupling matrix
\emph default
:
\begin_inset Formula 
\[
trace\left(W\right).
\]

\end_inset


\end_layout

\begin_layout Standard
A high metastability therefore denotes a high probability of staying in
 each cluster, once it is reached.
\end_layout

\begin_layout Standard
Note that this does not need to correspond with a high probability of the
 cluster.
\end_layout

\begin_layout Subsection
Example Processes
\end_layout

\begin_layout Standard
To demonstrate the connections between the different projections we now
 will show some example systems.
\end_layout

\begin_layout Paragraph
Example 1 - the decoupled system
\end_layout

\begin_layout Standard
Consider 
\begin_inset Formula $P=\left(\begin{array}{ccc}
\frac{1}{2} & \frac{1}{2} & 0\\
\frac{1}{2} & \frac{1}{2} & 0\\
0 & 0 & 1
\end{array}\right)$
\end_inset

.
 In this ideal decoupled system we have two invariant subspaces spanned
 by the so called 
\emph on
Perron eigenvectors 
\emph default
with eigenvalue 1, the vectors 
\begin_inset Formula $\left(\begin{array}{c}
1\\
1\\
0
\end{array}\right)$
\end_inset


\shape up
 and 
\shape default

\begin_inset Formula $\left(\begin{array}{c}
0\\
0\\
1
\end{array}\right)$
\end_inset

.

\shape up
 These can be interpreted as a discrete a 
\shape default
\emph on
crisp clustering
\emph default
, and assuming an equidistributed starting distribution we can compute the,
 in this case coinciding, matrices 
\begin_inset Formula $W=P_{C}=\left(\begin{array}{cc}
1 & 0\\
0 & 1
\end{array}\right).$
\end_inset


\end_layout

\begin_layout Paragraph
Example 2 - the 3-pot
\end_layout

\begin_layout Standard
Next we will consider the simpler process given by 
\begin_inset Formula $P:=\left(\begin{array}{ccc}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{array}\right)$
\end_inset

, i.e.
 the stationary markov chain on three states, but with the 
\emph on
fuzzy clustering 
\begin_inset Formula $\chi=\left(\begin{array}{cc}
1 & 0\\
\frac{1}{2} & \frac{1}{2}\\
0 & 1
\end{array}\right)$
\end_inset

.
 
\emph default
According to our definitions we now compute 
\begin_inset Formula $P_{C}:=\left(\begin{array}{cc}
1 & 0\\
0 & 1
\end{array}\right)$
\end_inset

 and 
\begin_inset Formula $W=\frac{1}{6}\left(\begin{array}{cc}
5 & 1\\
1 & 5
\end{array}\right)$
\end_inset

.

\emph on
 
\emph default
We see that 
\begin_inset Formula $P_{C}$
\end_inset

 contains the expected dynamics on the reduced state space, while 
\begin_inset Formula $W$
\end_inset

 still explains the probabilities on a micro scale.
\end_layout

\begin_layout Paragraph
Example 3 - negative entries
\end_layout

\begin_layout Standard
The following exampe will illustrate the occurence of negative entries in
 
\begin_inset Formula $P_{C}$
\end_inset

:
\begin_inset Formula 
\[
P=\frac{1}{4}\left(\begin{array}{cc}
1 & 3\\
3 & 1
\end{array}\right),\,\chi=\left(\begin{array}{cc}
1 & 0\\
0.5 & 0.5
\end{array}\right),\,\pi=\frac{1}{2}\left(\begin{array}{cc}
1 & 1\end{array}\right)
\]

\end_inset


\begin_inset Formula 
\[
P_{C}=\frac{1}{8}\left(\begin{array}{cc}
5 & 3\\
9 & -1
\end{array}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Now 
\begin_inset Formula $\left(0,1\right)\cdot P_{C}=\frac{1}{8}\left(9,-1\right)$
\end_inset

 gives us a linear combination which represents the distribution after applying
 P to the distribution represented by 
\begin_inset Formula $\left(0,1\right)$
\end_inset

, i.e.
\end_layout

\begin_layout Standard
So indeed even negative entries represent positive quantities, one might
 think of 
\begin_inset Formula $P_{C}$
\end_inset

 as acting with the basis of the clusters.
\end_layout

\begin_layout Paragraph
Example 4 - pert.
 of ex4
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P=\frac{1}{4}\left(\begin{array}{ccc}
1 & 3 & 0\\
2 & 1 & 1\\
0 & 3 & 1
\end{array}\right),\,\chi=\left(\begin{array}{cc}
1 & 0\\
\frac{1}{2} & \frac{1}{2}\\
0 & 1
\end{array}\right),\,\pi=\left(\frac{1}{3},\,\frac{1}{3},\,\frac{1}{3}\right)
\]

\end_inset


\end_layout

\begin_layout Section

\shape up
PCCA+
\end_layout

\begin_layout Standard
We now first present the PCCA+ algorithm in the case of reversible processes.
\end_layout

\begin_layout Standard
We first will construct the matrix 
\begin_inset Formula $X$
\end_inset

 spanning the invariant subspace, then examine the possible linear transformatio
ns 
\begin_inset Formula $A$
\end_inset

 mapping these to a set of membership vectors and finally propose an optimizatio
n problem to specify a 
\begin_inset Quotes eld
\end_inset

good
\begin_inset Quotes erd
\end_inset

 solution, representing the goal of metastability in the form of a objective
 function.
\end_layout

\begin_layout Subsection
Motivation for the spectral decomposition
\end_layout

\begin_layout Standard
PCCA+ will construct the clusters, described by the 
\emph on
membership vectors
\emph default
, as a linear combination of eigenvectors.
 This guarantees that 
\begin_inset Formula $\chi$
\end_inset

 spans an invariant subspace, whose dynamics is governed by the corresponding
 eigenvalues.
 By choosing the 
\begin_inset Formula $n<N$
\end_inset

 eigenvectors with the largest eigenvalues one hopes to preserve the principal
 dynamics of 
\begin_inset Formula $P$
\end_inset

.
 The eigenvectors are good data for this goal, as an eigenvector with high
 eigenvalue ....
\end_layout

\begin_layout Standard
//Eigenvalue lower bound for metastab.
\end_layout

\begin_layout Subsection
Reversible processes
\end_layout

\begin_layout Subsubsection
Construction of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $\Lambda$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sub:constrXL"

\end_inset


\end_layout

\begin_layout Standard
To satisfy the orthonormality condition 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:on"

\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
symmetric structure
\end_layout

\end_inset

we define the matrix 
\begin_inset Formula $\tilde{P}:=D_{\pi}^{\frac{1}{2}}PD_{\pi}^{-\frac{1}{2}}$
\end_inset

, where 
\begin_inset Formula $D_{\pi}$
\end_inset

 denotes the diagonal matrix with the stationary distribution 
\begin_inset Formula $\pi$
\end_inset

.
\end_layout

\begin_layout Standard
As we assume a reversible process the detailed balance condition 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:db"

\end_inset

 holds, assuring that 
\begin_inset Formula $\tilde{P}$
\end_inset

 is symmetric:
\begin_inset Formula 
\[
\tilde{P}^{T}=D_{\pi}^{-\frac{1}{2}}P^{T}D_{\pi}^{\frac{1}{2}}=D_{\pi}^{-\frac{1}{2}}D_{\pi}PD_{\pi}^{-1}D_{\eta}^{\frac{1}{2}}=\tilde{P}
\]

\end_inset


\end_layout

\begin_layout Standard
We therefore can diagonalize 
\begin_inset Formula $\tilde{P}$
\end_inset

 such that 
\begin_inset Formula $\tilde{P}\tilde{X'}=\tilde{X'}\Lambda'$
\end_inset

 with 
\begin_inset Formula $\tilde{X'}\in\mathbb{R}^{N\times N}$
\end_inset

 beeing orthonormal and 
\begin_inset Formula $\Lambda'\in\mathbb{R}^{N\times N}$
\end_inset

 beeing diagonal.
\end_layout

\begin_layout Standard
We then select the 
\begin_inset Formula $n$
\end_inset

 largest eigenvalues 
\begin_inset Formula $\Lambda\in\mathbb{R}^{n\times n}$
\end_inset

 and the corresponding eigenvectors 
\begin_inset Formula $\tilde{X}\in\mathbb{R}^{N\times n},$
\end_inset

 and define 
\begin_inset Formula $X:=D_{\pi}^{-\frac{1}{2}}\tilde{X}$
\end_inset

.
\end_layout

\begin_layout Standard
We then see that the conditions for 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:comm"

\end_inset

 are satisfied:
\begin_inset Formula 
\begin{eqnarray*}
\tilde{P}\tilde{X} & = & \tilde{X}\Lambda\\
\Leftrightarrow D_{\pi}^{\frac{1}{2}}PD_{\pi}^{-\frac{1}{2}}D_{\pi}^{\frac{1}{2}}X & = & D_{\pi}^{\frac{1}{2}}X\Lambda\\
\Leftrightarrow PX & = & X\Lambda
\end{eqnarray*}

\end_inset


\begin_inset Formula 
\begin{eqnarray*}
\tilde{X}^{T}\tilde{X} & = & I\\
\Leftrightarrow X^{T}D_{\pi}^{\frac{1}{2}}D_{\pi}^{\frac{1}{2}}X & = & I\\
\Leftrightarrow X^{T}D_{\pi}X & = & I
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsubsection
Feasible Set
\end_layout

\begin_layout Standard
Given a fixed eigenvector matrix 
\begin_inset Formula $X$
\end_inset

, we will now examine the set of feasible solutions 
\begin_inset Formula $F_{A}\subset\mathbb{R}^{n\times n}$
\end_inset

 for the transformation matrix 
\begin_inset Formula $A$
\end_inset

, defined by the leading to 
\emph on
membership vectors
\emph default
 
\begin_inset Formula $\chi=XA$
\end_inset

.
\end_layout

\begin_layout Standard
Making use of the fact that 
\begin_inset Formula $X_{i,1}=1,\, i=1,...,N$
\end_inset

 (reference?) one can reformulate the positivity 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:pos"

\end_inset

 and partition of unity 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:pu"

\end_inset

 conditions in terms of the matrices X and A, leading to the following constrain
ts for A:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
A_{1,j} & \ge & -\sum_{k=2}^{n}X_{ik}A_{kj},\, i=1,...,N,\, j=1,...,n\,\left(\text{positivity}\right),\label{eq:fa}\\
A_{i,1} & = & \delta_{i,1}-\sum_{j=2}^{n}A_{ij},\, i=1,...,n\,\left(\text{partition of unity}\right)
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
Since these constraints are linear in A the set 
\begin_inset Formula $F_{A}$
\end_inset

 is a convex polytope, and it is not empty as the matrix 
\begin_inset Formula $A_{ij}^{*}:=\frac{\delta_{i,1}}{n}$
\end_inset

 satisfies these conditions.
\end_layout

\begin_layout Standard
As Deuflhard and Weber 
\begin_inset CommandInset citation
LatexCommand cite
key "Deuflhard2005"

\end_inset

 have shown, the set 
\begin_inset Formula $F_{A}$
\end_inset

 is indeed uncountable.
 We therefore look for some criterion to choose a specific solution by means
 of choosing an objective function for an optimization problem.
 To motivate the specific choices we first try to gain some insight into
 the geometry of the clustering problem.
\end_layout

\begin_layout Subsubsection
Geometric interpretation
\end_layout

\begin_layout Standard
If one considers the 
\begin_inset Formula $N$
\end_inset

 rows of the matrix 
\begin_inset Formula $\chi$
\end_inset

 as points in the space 
\begin_inset Formula $\mathbb{R}^{n}$
\end_inset

, the positivity and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:pos"

\end_inset

 and partition of unity 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:pu"

\end_inset

 conditions force these points to lie on the standard 
\begin_inset Formula $\left(n-1\right)$
\end_inset

-simplex 
\begin_inset Formula $\Delta$
\end_inset

.
 Now, if 
\begin_inset Formula $\chi=XA$
\end_inset

 this means the that the matrix 
\begin_inset Formula $A$
\end_inset

 maps the the 
\begin_inset Formula $N$
\end_inset

 rows of the eigenvector matrix 
\begin_inset Formula $X$
\end_inset

 onto that simplex.
 
\end_layout

\begin_layout Standard
Assuming (
\emph on
maximality assumption) 
\emph default
that the convex hull 
\begin_inset Formula $\text{co}\left(X\right)$
\end_inset

 of the rows of 
\begin_inset Formula $X$
\end_inset

 already has the form of an 
\begin_inset Formula $\left(n-1\right)$
\end_inset

-simplex, we can now choose 
\begin_inset Formula $A$
\end_inset

 uniquely (up to permutation) to map this exactly onto 
\begin_inset Formula $\Delta$
\end_inset

, which among all the ways of mapping 
\begin_inset Formula $X$
\end_inset

 into 
\begin_inset Formula $\Delta$
\end_inset

 gives us the highest distinguishability between the resulting clusters.
 This assumption is equivalent to the situation that for each corner there
 exists a row getting mapped into that corner, i.e.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\max_{i=1..N}\chi_{ij}=1,\, j=1,...,n,
\]

\end_inset

justifying its name.
\end_layout

\begin_layout Standard
(Upper bound for metastability on 
\begin_inset Formula $W$
\end_inset

)
\end_layout

\begin_layout Subsubsection
Maximal scaling condition
\end_layout

\begin_layout Standard
As in the general the 
\emph on
maximality assumption
\emph default
 is not met, it seems natural to turn it into an optimization problem.
 This has been done in 
\begin_inset CommandInset citation
LatexCommand cite
key "Deuflhard2005,Weber2006"

\end_inset

 by imposing maximization of the 
\emph on
maximal scaling condition 
\begin_inset Formula 
\[
I_{1}\left(A\right):=\sum_{j=1}^{n}\max_{i=1..N}\chi_{ij}\le n_{C}.
\]

\end_inset


\end_layout

\begin_layout Standard
Assuming that the 
\emph on
maximality assumption
\emph default
 is almost met, i.e.
 
\begin_inset Formula $\max_{i=1..N}\chi_{ij}\approx1,\, j=1,...,n$
\end_inset

, Weber 
\begin_inset CommandInset citation
LatexCommand cite
key "Weber2006"

\end_inset

 argues that the maximizing indices can be determined by the 
\emph on
index mapping algortithm
\emph default
, turning this convex optimization problem into a linear one:
\begin_inset Formula 
\[
I_{1}\left(A\right)=\sum_{i,j=1}^{n}X_{ind\left(X\right)_{j},i}A_{ij}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Maximal metastability condition
\end_layout

\begin_layout Standard
Another choice might be optimizing towards a maximal metastability, as done
 by Deuflhard and Weber 
\begin_inset CommandInset citation
LatexCommand cite
key "Deuflhard2005,Weber2006"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
I_{2}\left(A\right):=\text{trace}\left(W\right)=\sum_{i=1}^{n}\lambda_{i}\sum_{j=1}^{n}\frac{A\left(i,j\right)^{2}}{A\left(1,j\right)},
\]

\end_inset

where they establish the latter equation making use of 
\begin_inset Formula $\pi_{i}=A_{1,i}$
\end_inset

 (
\begin_inset CommandInset citation
LatexCommand cite
key "Weber2006"

\end_inset

, Lemma 3.6).
\end_layout

\begin_layout Subsubsection
Crispness objective
\end_layout

\begin_layout Standard
Röblitz 
\begin_inset CommandInset citation
LatexCommand cite
key "Roeblitz2013"

\end_inset

 argues that the use of 
\begin_inset Formula $W$
\end_inset

 has no stochastic interpretation in the fuzzy setting.
 Optimization of the trace of 
\begin_inset Formula $P_{C}$
\end_inset

 makes no sense as it is similar to 
\begin_inset Formula $\Lambda$
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "eq:conj"

\end_inset

 and therefore independent of 
\begin_inset Formula $A$
\end_inset

.
 Defining 
\begin_inset Formula 
\[
\mathcal{S}=..\chi^{T}D_{\pi}\chi
\]

\end_inset

she therefore suggests maximization of 
\begin_inset Formula 
\[
I_{3}:=\text{trace}\left(\mathcal{S}\right)=\sum_{i,j=1}^{n}\frac{\left(A_{ij}\right)^{2}}{A_{1,j}}.
\]

\end_inset

which is similar to 
\begin_inset Formula $I_{2}$
\end_inset

 ....
\end_layout

\begin_layout Standard
This condition minimizes the off-diagonal entries of 
\begin_inset Formula $\mathcal{S}$
\end_inset

 which means that the corresponding clustering 
\begin_inset Formula $\chi$
\end_inset

 is as crisp as possible.
\end_layout

\begin_layout Subsubsection
Unconstrained Optimization
\end_layout

\begin_layout Standard
Due to the high number of inequality constraints 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:fa"

\end_inset

 solving these linear or convex problems may still be very time consuming.
 Following Deuflhard and Weber 
\begin_inset CommandInset citation
LatexCommand cite
key "Deuflhard2005,Weber2006"

\end_inset

 we will now show how to turn this constrained into an unconstrained optimizatio
n problem.
\end_layout

\begin_layout Standard
Define the set 
\begin_inset Formula $F_{A}^{'}$
\end_inset

 by the equality constraints 
\begin_inset Formula 
\begin{eqnarray}
A_{i,1} & = & \delta_{i,1}-\sum_{j=2}^{n}A_{ij},\, i=1,...,n\nonumber \\
A_{1,j} & = & -\min_{l=1,...,N}\sum_{i=2}^{n}X_{li}A_{ij},\, j=1,....,n.\label{eq:fap}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
Comparing these equalities to 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:fa"

\end_inset

 one easily checks that 
\begin_inset Formula $F_{A}^{'}\subset F_{A}$
\end_inset

.
 Furthermore, as Weber shows in 
\begin_inset CommandInset citation
LatexCommand cite
key "Weber2006"

\end_inset

 (Lemma 3.5), the vertex set 
\begin_inset Formula $v\left(F_{A}\right)\subset F_{A}^{'}$
\end_inset

 is still contained in this restriced set.
\end_layout

\begin_layout Standard
Now consider the 
\emph on
feasabilization
\emph default
 
\emph on
algorithm
\emph default
 
\begin_inset Formula $F:\mathbb{R}^{\left(n-1\right)\times\left(n-1\right)}\twoheadrightarrow F_{A}^{'}$
\end_inset

, mapping any arbitrary matrix 
\begin_inset Formula $\left(\tilde{A}_{ij}\right)_{i,j=2,...,n}$
\end_inset

 to a feasable transformation matrix 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Paragraph
Feasabilization algorithm
\begin_inset CommandInset label
LatexCommand label
name "par:algfeas"

\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $i=2,....,n$
\end_inset

 define 
\begin_inset Formula $\tilde{A}_{i,1}:=-\sum_{j=2}^{n}\tilde{A}_{ij}$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $j=1,...,n$
\end_inset

 define 
\begin_inset Formula $\tilde{A}_{1,j}:=-\min_{l=1,...,N}\sum_{i=2}^{n}X_{li}\tilde{A}_{ij}$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $i,j=1,...,n$
\end_inset

 define 
\begin_inset Formula $A_{ij}:=\frac{\tilde{A}_{ij}}{\sum_{j=1}^{k}\tilde{A}_{1,j}}$
\end_inset


\end_layout

\begin_layout Standard
Steps 1 and 2 guarantee feasability of 
\begin_inset Formula $\tilde{A}$
\end_inset

 with respect to 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:fap"

\end_inset

 for 
\begin_inset Formula $i=2,...,n$
\end_inset

 respectively 
\begin_inset Formula $j=1,...,n$
\end_inset

.
 As these equalities are linear in 
\begin_inset Formula $A$
\end_inset

 they are invariant under scalar multiplication and step 3 now furthermore
 assures the equality 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:fap"

\end_inset

 for 
\begin_inset Formula $i=1$
\end_inset

.
 Thus F indeed maps to 
\begin_inset Formula $F_{A}^{'}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Furthermore, taking any matrix 
\begin_inset Formula $A\in F_{A}^{'}$
\end_inset

, dropping the first row and column to get 
\begin_inset Formula $\tilde{A}$
\end_inset

 and computing 
\begin_inset Formula $F\left(\tilde{A}\right)=A$
\end_inset

 we see that F is surjective.
\end_layout

\begin_layout Standard
As any objective function 
\begin_inset Formula $I_{i},\, i=1,2,3$
\end_inset

 is convex over 
\begin_inset Formula $F_{A}$
\end_inset

 it attains its maximum at one of the vertices 
\begin_inset Formula $v\left(F_{A}\right)$
\end_inset

.
 We thus can also optimize the function 
\begin_inset Formula $F\circ I_{i}$
\end_inset

 over 
\begin_inset Formula $\mathbb{R}^{\left(n-1\right)\times\left(n-1\right)}$
\end_inset

 and so have transformed the constrained optimization problem in 
\begin_inset Formula $n^{2}$
\end_inset

 unknows to an unconstrained in 
\begin_inset Formula $\left(n-1\right)^{2}$
\end_inset

 unknows.
\end_layout

\begin_layout Standard
Next we will develop an initial guess to this global optimization problem,
 turning it into a local one.
\end_layout

\begin_layout Subsubsection
Inner simplex algorithm
\end_layout

\begin_layout Standard
Based on Weber and Galliat 
\begin_inset CommandInset citation
LatexCommand cite
key "Weber2002"

\end_inset

 we outline the
\emph on
 inner simplex algorithm
\emph default
, determining an initial guess for the matrix 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Standard
The first step
\emph on
, 
\emph default
the 
\emph on
index mapping algorithm, 
\emph default
looks for the indices 
\begin_inset Formula $i_{j}$
\end_inset

 of the succesively farthest linear independent rows.
 It starts by choosing the largest row vector as starting point, and then
 iteratively adds the points with the largest distance to the hyperplane
 spanned by the chosen points so far:
\end_layout

\begin_layout Paragraph
Index mapping algorithm
\end_layout

\begin_layout Enumerate
Find starting point: 
\begin_inset Formula $i_{1}:=\text{argmax}_{j\in C}\left\Vert X_{\cdot,j}\right\Vert _{^{2}}$
\end_inset


\begin_inset Newline newline
\end_inset

Translate to origin: For 
\begin_inset Formula $i\in S$
\end_inset

 set 
\begin_inset Formula $X_{i,\cdot}\mapsfrom X_{i,\cdot}-X_{i_{1},\cdot}$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $j=2,...,n$
\end_inset


\begin_inset Newline newline
\end_inset

Find next index: 
\begin_inset Formula $i_{j}:=\text{argmax}_{j\in C}\left\Vert X_{\cdot,j}\right\Vert _{^{2}}$
\end_inset


\begin_inset Newline newline
\end_inset

Projection to hyperplane by Gram-Schmidt process: 
\begin_inset Formula $X\mapsfrom X-\frac{\text{XX_{i_{j},\cdot}^{T}\otimes X_{i_{j},\cdot}}}{\left\Vert X_{i_{j},\cdot}\right\Vert _{2}}$
\end_inset

 
\end_layout

\begin_layout Standard
Once having determined the indices of the 
\begin_inset Formula $n$
\end_inset

 extremal points, we now construct the matrix 
\begin_inset Formula $A$
\end_inset

 mapping these to the vertices of 
\begin_inset Formula $\Delta$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
A\left(X\right):=\left(X_{ij}\right)_{i=i_{1},...,i_{n},\, j=1,...,n}^{-1}
\]

\end_inset


\end_layout

\begin_layout Standard
In the case of the 
\emph on
maximality assumption
\emph default
, 
\begin_inset Formula $X$
\end_inset

 spans a 
\begin_inset Formula $\left(n-1\right)$
\end_inset

-simplex, and the 
\emph on
index mapping algorithm 
\emph default
determines its vertices, thus 
\begin_inset Formula $X\cdot\text{co}\left(x\right)=\Delta$
\end_inset

 and 
\begin_inset Formula $X\in v\left(F_{A}\right)$
\end_inset

 maximizes 
\begin_inset Formula $I_{1}$
\end_inset

.
\end_layout

\begin_layout Standard
For the general case though Weber 
\begin_inset CommandInset citation
LatexCommand cite
key "Weber2006"

\end_inset

 (Lemma 3.13, Theorem 3.14) has shown that the following statements are equivalent
:
\end_layout

\begin_layout Enumerate
The convex hull 
\begin_inset Formula $\text{co}\left(X\right)$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

 is a simplex.
\end_layout

\begin_layout Enumerate
The result of the 
\emph on
inner simplex algorithm
\emph default
 is feasible, i.e.
 
\begin_inset Formula $A\in F_{A}$
\end_inset

.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $A\in v\left(F_{A}\right)$
\end_inset

 and therefore maximizes 
\begin_inset Formula $I_{1}$
\end_inset

.
\end_layout

\begin_layout Standard
Therefore the result is not feasible in the generic case.
\end_layout

\begin_layout Standard
If however the 
\emph on
maximality assumption 
\emph default
almost holds, i.e.
 the convex hull of X is a small pertubation of a simplex, which according
 to Weber 
\begin_inset CommandInset citation
LatexCommand cite
key "Weber2006"

\end_inset

 (3.4.4) is satisfied in most of the applications, the algorithm still gives
 a solution near the unperturbed solution.
\end_layout

\begin_layout Standard
Therefore that 
\begin_inset Formula $A$
\end_inset

 is near a vertex of the set 
\begin_inset Formula $F_{A}$
\end_inset

 and thus a good initial guess for a local optimization of the unconstraint
 optimization.
\end_layout

\begin_layout Subsubsection
The PCCA+ Algorithm
\end_layout

\begin_layout Enumerate
Compute 
\begin_inset Formula $X,\,\Lambda$
\end_inset

 as in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:constrXL"

\end_inset


\end_layout

\begin_layout Enumerate
Determine the, in general infeasible, initial guess 
\begin_inset Formula $A_{0}:=A\left(X\right)$
\end_inset

 using the 
\emph on
inner simplex algorithm
\emph default
.
\end_layout

\begin_layout Enumerate
Perform an iterative local optimization 
\begin_inset Formula $A_{0},\, A_{1},...$
\end_inset

 of the objective function 
\begin_inset Formula $I_{1}$
\end_inset

, 
\begin_inset Formula $I_{2}$
\end_inset

 or 
\begin_inset Formula $I_{3}$
\end_inset

.
 In each step 
\begin_inset Formula $A_{k}\rightarrow A_{k+1}$
\end_inset

 only update the elements 
\begin_inset Formula $A_{k,ij},\, i,j\not=1$
\end_inset

 without constraints.
 Then use algorithm
\emph on
 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:algfeas"

\end_inset

 
\emph default
to get a feasible matrix 
\begin_inset Formula $A_{k}$
\end_inset

 before evaluating the corresponding objective function.
\end_layout

\begin_layout Standard
As the 
\emph on
feasibalization algorithm 
\emph default
is not differentiable, Deuflhard and Weber 
\begin_inset CommandInset citation
LatexCommand cite
key "Deuflhard2005"

\end_inset

 propose the use of the nonlinear simplex method of Nelder and Mead 
\begin_inset CommandInset citation
LatexCommand cite
key "Nelder1965"

\end_inset

 as local optimization routine.
\end_layout

\begin_layout Subsubsection
Determination of the number of clusters 
\begin_inset Formula $n$
\end_inset


\end_layout

\begin_layout Standard
So far we have imposed a desired number of clusters 
\begin_inset Formula $n$
\end_inset

.
\end_layout

\begin_layout Subsection

\shape up
Nonreversible processes
\end_layout

\begin_layout Standard
The whole algorithm is also applicable to nonreversible processes, with
 some smaller adjustments concerning the construction of the invariant subspace
 and the stochastic interpretation, as well as a new optimization goal.
\end_layout

\begin_layout Subsubsection
Stochastic interpretation of the coupling matrix
\begin_inset CommandInset label
LatexCommand label
name "sub:stochintnr"

\end_inset


\end_layout

\begin_layout Subsubsection
Construction of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $\Lambda$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sub:weightedss"

\end_inset


\end_layout

\begin_layout Standard
When the underlying stochastic process is not reversible the matrix 
\begin_inset Formula $P$
\end_inset

 is no more real diagonalizable.
 We therefore make use of the
\emph on
 real Schur decomposition
\emph default
, decomposing a matrix 
\begin_inset Formula $A=QTQ^{-1}$
\end_inset

 into a orthonormal
\emph on
 
\emph default
matrix 
\begin_inset Formula $Q$
\end_inset

, called the 
\emph on
Schur vectors,
\emph default
 and an upper quasi-triangular (1-by-1 and 2-by-2 blocks on its diagonal)
 matrix 
\begin_inset Formula $T$
\end_inset

, called the 
\emph on
Schur form
\emph default
.
 The columns of 
\begin_inset Formula $Q$
\end_inset

 are called the Schur vectors of 
\begin_inset Formula $P$
\end_inset

.
 The eigenvalues of 
\begin_inset Formula $P$
\end_inset

 appear on the diagonal of 
\begin_inset Formula $T$
\end_inset

, where complex conjugate eigenvalues correspond to the 2-by-2 blocks.
 
\end_layout

\begin_layout Standard
To compute an orthonormal basis for an invariant subspace belonging to 
\begin_inset Formula $n$
\end_inset

 eigenvalues one can reorder the diagonal blocks of 
\begin_inset Formula $T$
\end_inset

 such that the upper left 
\begin_inset Formula $n\times n$
\end_inset

 block contains these 
\begin_inset Formula $n$
\end_inset

 eigenvalues.
 Then the first 
\begin_inset Formula $n$
\end_inset

 columns of the updated transformation matrix 
\begin_inset Formula $Q$
\end_inset

 form a basis for the desired subspace 
\begin_inset CommandInset citation
LatexCommand cite
key "schur"

\end_inset

.
\end_layout

\begin_layout Standard
So we define, analogously to 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:constrXL"

\end_inset

 
\begin_inset Formula $\tilde{P}:=D_{\eta}^{\frac{1}{2}}PD_{\eta}^{-\frac{1}{2}}$
\end_inset

 and compute the 
\emph on
real Schur decomposition 
\emph default
of 
\begin_inset Formula $\tilde{P}$
\end_inset

.
 We then select the 
\begin_inset Formula $n\times n$
\end_inset

 blocks corresponding to the 
\begin_inset Formula $n$
\end_inset

 eigenvalues with the highest absolute value by the reordering procedure.
 Let us denote the resulting 
\emph on
Schur vectors 
\emph default
by 
\begin_inset Formula $\tilde{X}$
\end_inset

 and the 
\emph on
Schur form 
\emph default
by 
\begin_inset Formula $\Lambda$
\end_inset

.
 
\end_layout

\begin_layout Standard
Now 
\begin_inset Formula $X:=D_{\pi}^{-\frac{1}{2}}\tilde{X}$
\end_inset

 and 
\begin_inset Formula $\Lambda$
\end_inset

 satisfy the conditions for 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:comm"

\end_inset

 (same calculations as in
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:constrXL"

\end_inset

 ).
\end_layout

\begin_layout Subsubsection
Optimization
\end_layout

\begin_layout Standard
Not only metastable, but also cyclic dynamics of interest.
\end_layout

\begin_layout Section

\shape up
Application to eyetracking data
\end_layout

\begin_layout Standard
This algorithm was applied to experimental eye-tracking data obtained by
 the department of psychology of the Universität Potsdam, with the goal
 to detect objects as metastable clusters using just the dynamics of the
 human eye, i.e.
 without any data of the image itself.
\end_layout

\begin_layout Subsection
The experiment
\end_layout

\begin_layout Standard
A group of test persons was presented an image for the duration of ...
\end_layout

\begin_layout Standard
The eye-tracker measures the fixations 
\begin_inset Formula $f_{i}\in\mathbb{R}^{2}$
\end_inset

 of the test persons eyes and their respective time 
\begin_inset Formula $t_{i}\in\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout Standard
This experiment was repeated with the same images mirrored horizontally,
 to test in how far our perception of images is influenced by its horizontal
 orientation.
\end_layout

\begin_layout Subsection
Implementation
\end_layout

\begin_layout Standard
As state space we define the coordinates of each fixation 
\begin_inset Formula $S:=\left\{ s_{i}\right\} ,\, s_{i}=f_{i}$
\end_inset

, though if one has too many fixations one can precluster the fixations
 for example with k-means.
\end_layout

\begin_layout Standard
We then compute the membership of each fixation 
\begin_inset Formula $f_{i}$
\end_inset

 to each state 
\begin_inset Formula $s_{j}$
\end_inset

 based on the row-sum normalized gaussian of the distance:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
M_{ij}:=\frac{e^{\frac{\left|f_{i}-s_{j}\right|^{2}}{2\sigma^{2}}}}{\sum_{j}e^{\frac{\left|f_{i}-s_{j}\right|^{2}}{2\sigma^{2}}}}
\]

\end_inset


\end_layout

\begin_layout Standard
// check the 2
\end_layout

\begin_layout Standard
This assures that nearby fixations 
\begin_inset Quotes eld
\end_inset

overlap
\begin_inset Quotes erd
\end_inset

, introducing the metric distance information contained in the fixation
 data to the markov process.
\end_layout

\begin_layout Standard
We then fix a step time 
\begin_inset Formula $\tau=50\text{ms}$
\end_inset

 for the markov chain to compute the transitions along this time-grid.
\end_layout

\begin_layout Standard
Then summing the state correspondances over all fixation transitions 
\begin_inset Formula $f_{a}\rightarrow f_{b},$
\end_inset

 and normalizing to row sum 
\begin_inset Formula $1$
\end_inset

 we define the 
\emph on
transition matrix
\emph default
 
\begin_inset Formula $P$
\end_inset

:
\begin_inset Formula 
\begin{eqnarray*}
\\
P_{ij} & = & \frac{\sum_{f_{a}\rightarrow f_{b}}M_{ai}M_{bj}}{\sum_{k}\sum_{f_{a}\rightarrow f_{b}}M_{ai}M_{bk}}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
We define the stationary distrubution at the i-th state as the normalized
 amount of counted transitions from that state:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\pi_{i}=\frac{\sum_{f_{a}\rightarrow f_{b}}M_{ai}}{\sum_{i}\sum_{f_{a}\rightarrow f_{b}}M_{ai}}
\]

\end_inset


\end_layout

\begin_layout Standard
Once we have constructed 
\begin_inset Formula $P$
\end_inset

 this way we now compute the invariant eigenspace using the weighted Schur
 decomposition as in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:weightedss"

\end_inset

 and pass is to PCCA+, which in return gives us the clustering 
\begin_inset Formula $\chi$
\end_inset

, with which we also can compute the 
\emph on
coupling matrix
\emph default
 on our reduced state space.
\end_layout

\begin_layout Standard
To allow for comparison of two different experiments we reorder the clusters
 such that their respective correlation is maximized:
\end_layout

\begin_layout Standard
We define the correlation of two clusters as sum over all products of the
 gaussians of the states weighted with their cluster share.
 We now use the Hungarian algorithm to reorder the matrix to maximize the
 diagonal.
\end_layout

\begin_layout Standard
For the comparison of two experiments, A and B, different methods were implement
ed:
\end_layout

\begin_layout Itemize
Direct: One can either compare the different 
\emph on
coupling matrices 
\emph default
directly which each other, using their respective clustering.
\end_layout

\begin_layout Itemize
Coupling average: Apply each resulting clustering to each experiment and
 compute the average of the difference of the coupling matrices.
\end_layout

\begin_layout Itemize
Cluster average: Compute the average clustering and compare the corresponding
 
\emph on
coupling matrices 
\emph default
directly.
\end_layout

\begin_layout Subsection
Results
\end_layout

\begin_layout Section

\shape up
Junk
\end_layout

\begin_layout Subsubsection
Stochastic interpretation
\end_layout

\begin_layout Standard
By multiplying the conditional transitions of 
\begin_inset Formula $P$
\end_inset

 with the actual starting distribution we get the unconditional transitions
 matrix 
\begin_inset Formula $D_{\eta}P$
\end_inset

, which we can interpret as amount of actual transitions between the states.
 Now multiplying with a membership vector 
\begin_inset Formula $\chi_{i}^{T}$
\end_inset

 from the left gives the numbers of transitions starting in 
\begin_inset Formula $\chi_{i}$
\end_inset

 and finally multiplying with 
\begin_inset Formula $\chi_{j}$
\end_inset

 from the right measures the amount of these transitions landing in 
\begin_inset Formula $\chi_{j}$
\end_inset

, i.e.
 
\begin_inset Formula $\chi_{i}^{T}D_{\eta}P\chi_{j}$
\end_inset

.
\end_layout

\begin_layout Standard
gives the unconditional number of transitions from cluster 
\begin_inset Formula $i$
\end_inset

 to cluster 
\begin_inset Formula $j$
\end_inset

.
 Note that this interpretation is associative in the sense that we come
 to the same results by for example first interpreting 
\begin_inset Formula $\chi_{i}^{T}D_{\eta}$
\end_inset

 as actual amount of states in the cluster 
\begin_inset Formula $\chi_{i}$
\end_inset

 and measure the overlap with where the transitions to 
\begin_inset Formula $\chi_{j}$
\end_inset

, come from: 
\begin_inset Formula $\left(\chi_{i}^{T}D_{\eta}\right)(P\chi_{j})$
\end_inset

.
\end_layout

\begin_layout Standard
We can vectorize this equation to compute the unconditional transitions
 by means of the 
\emph on
membership matrix 
\begin_inset Formula $\chi=\left(\chi_{1},...,\chi_{n}\right)$
\end_inset

:
\begin_inset Formula 
\[
\chi^{T}D_{\eta}P\chi
\]

\end_inset


\end_layout

\begin_layout Standard
We then turn this unconditional transitions into conditinal by dividing
 by the number of states belonging to 
\begin_inset Formula $\chi_{i}$
\end_inset

 and have to make up the fact that we do not count all transitions...
 Baustelle
\end_layout

\begin_layout Standard

\shape up
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "ba"
options "bibtotoc,plain"

\end_inset


\end_layout

\end_body
\end_document
